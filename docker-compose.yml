# ML Arsenal - Docker Compose Configuration
# =========================================
# Complete development and production environment setup

version: '3.8'

# =============================================================================
# Services
# =============================================================================

services:
  # -----------------------------------------------------------------------------
  # ML Arsenal Application
  # -----------------------------------------------------------------------------
  ml-arsenal:
    build:
      context: .
      dockerfile: Dockerfile
      target: runtime
      args:
        BUILD_DATE: ${BUILD_DATE:-$(date -u +'%Y-%m-%dT%H:%M:%SZ')}
        VCS_REF: ${VCS_REF:-$(git rev-parse --short HEAD)}
        VERSION: ${VERSION:-latest}
    image: ml-arsenal:${VERSION:-latest}
    container_name: ml-arsenal-app
    restart: unless-stopped
    
    # Environment variables
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DATABASE_URL=${DATABASE_URL:-postgresql://ml_user:ml_password@postgres:5432/ml_arsenal}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI:-http://mlflow:5000}
      - MONITORING_ENABLED=${MONITORING_ENABLED:-true}
    
    # Ports
    ports:
      - "${ML_ARSENAL_PORT:-8080}:8080"
    
    # Volumes
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./configs:/app/configs
      - ./logs:/app/logs
      - ./experiments:/app/experiments
      - ./reports:/app/reports
    
    # Dependencies
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # -----------------------------------------------------------------------------
  # ML Arsenal GPU (optional)
  # -----------------------------------------------------------------------------
  ml-arsenal-gpu:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      args:
        BUILD_DATE: ${BUILD_DATE:-$(date -u +'%Y-%m-%dT%H:%M:%SZ')}
        VCS_REF: ${VCS_REF:-$(git rev-parse --short HEAD)}
        VERSION: ${VERSION:-latest}
    image: ml-arsenal-gpu:${VERSION:-latest}
    container_name: ml-arsenal-gpu
    restart: unless-stopped
    profiles: ["gpu"]
    
    # GPU runtime
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - CUDA_VISIBLE_DEVICES=0
    
    ports:
      - "${ML_ARSENAL_GPU_PORT:-8081}:8080"
    
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./configs:/app/configs
      - ./logs:/app/logs
      - ./experiments:/app/experiments
    
    depends_on:
      - postgres
      - redis
      - mlflow
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # -----------------------------------------------------------------------------
  # PostgreSQL Database
  # -----------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    container_name: ml-arsenal-postgres
    restart: unless-stopped
    
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-ml_arsenal}
      - POSTGRES_USER=${POSTGRES_USER:-ml_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ml_password}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ml_user} -d ${POSTGRES_DB:-ml_arsenal}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # -----------------------------------------------------------------------------
  # Redis Cache
  # -----------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: ml-arsenal-redis
    restart: unless-stopped
    
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis_password}
    
    ports:
      - "${REDIS_PORT:-6379}:6379"
    
    volumes:
      - redis_data:/data
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # -----------------------------------------------------------------------------
  # MLflow Tracking Server
  # -----------------------------------------------------------------------------
  mlflow:
    image: python:3.9-slim
    container_name: ml-arsenal-mlflow
    restart: unless-stopped
    
    command: >
      bash -c "
        pip install mlflow psycopg2-binary &&
        mlflow server
          --host 0.0.0.0
          --port 5000
          --backend-store-uri postgresql://${POSTGRES_USER:-ml_user}:${POSTGRES_PASSWORD:-ml_password}@postgres:5432/${POSTGRES_DB:-ml_arsenal}
          --default-artifact-root /mlflow/artifacts
          --serve-artifacts
      "
    
    environment:
      - MLFLOW_TRACKING_URI=postgresql://${POSTGRES_USER:-ml_user}:${POSTGRES_PASSWORD:-ml_password}@postgres:5432/${POSTGRES_DB:-ml_arsenal}
    
    ports:
      - "${MLFLOW_PORT:-5000}:5000"
    
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
    
    depends_on:
      postgres:
        condition: service_healthy
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # -----------------------------------------------------------------------------
  # Jupyter Lab (Development)
  # -----------------------------------------------------------------------------
  jupyter:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    image: ml-arsenal-dev:${VERSION:-latest}
    container_name: ml-arsenal-jupyter
    restart: unless-stopped
    profiles: ["development"]
    
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-ml_arsenal_token}
    
    ports:
      - "${JUPYTER_PORT:-8888}:8888"
    
    volumes:
      - ./notebooks:/app/notebooks
      - ./src:/app/src
      - ./data:/app/data
      - ./models:/app/models
      - ./experiments:/app/experiments
    
    command: >
      jupyter lab
        --ip=0.0.0.0
        --port=8888
        --no-browser
        --allow-root
        --NotebookApp.token=${JUPYTER_TOKEN:-ml_arsenal_token}
        --NotebookApp.password=''

  # -----------------------------------------------------------------------------
  # Monitoring Stack
  # -----------------------------------------------------------------------------
  
  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: ml-arsenal-prometheus
    restart: unless-stopped
    profiles: ["monitoring"]
    
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
  
  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: ml-arsenal-grafana
    restart: unless-stopped
    profiles: ["monitoring"]
    
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
    
    depends_on:
      - prometheus

  # -----------------------------------------------------------------------------
  # Testing and Quality Assurance
  # -----------------------------------------------------------------------------
  
  # Test runner
  test-runner:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    image: ml-arsenal-dev:${VERSION:-latest}
    container_name: ml-arsenal-tests
    profiles: ["testing"]
    
    command: >
      bash -c "
        python -m pytest tests/ -v --cov=src --cov-report=html --cov-report=term &&
        python -m pytest tests/performance/ --benchmark-only
      "
    
    volumes:
      - ./src:/app/src
      - ./tests:/app/tests
      - ./htmlcov:/app/htmlcov
    
    environment:
      - TESTING=true
      - DATABASE_URL=postgresql://test_user:test_password@postgres-test:5432/test_db
  
  # Test database
  postgres-test:
    image: postgres:15-alpine
    container_name: ml-arsenal-postgres-test
    profiles: ["testing"]
    
    environment:
      - POSTGRES_DB=test_db
      - POSTGRES_USER=test_user
      - POSTGRES_PASSWORD=test_password
    
    volumes:
      - postgres_test_data:/var/lib/postgresql/data

# =============================================================================
# Networks
# =============================================================================

networks:
  default:
    name: ml-arsenal-network
    driver: bridge

# =============================================================================
# Volumes
# =============================================================================

volumes:
  postgres_data:
    driver: local
  postgres_test_data:
    driver: local
  redis_data:
    driver: local
  mlflow_artifacts:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# =============================================================================
# Usage Examples
# =============================================================================

# Development environment:
# docker-compose --profile development up -d

# Production environment:
# docker-compose up -d ml-arsenal postgres redis mlflow

# GPU environment:
# docker-compose --profile gpu up -d ml-arsenal-gpu postgres redis mlflow

# Full monitoring stack:
# docker-compose --profile monitoring up -d

# Testing:
# docker-compose --profile testing up test-runner

# All services:
# docker-compose --profile development --profile monitoring --profile gpu up -d
