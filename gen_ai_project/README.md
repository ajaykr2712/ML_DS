# ğŸ¤– Generative AI Project

A comprehensive implementation of various generative AI models including GPT, VAE, GAN, and Diffusion models.

## ğŸ¯ Overview

This project provides production-ready implementations of state-of-the-art generative models with clear examples, extensive documentation, and modular architecture.

### ğŸš€ Features

- **GPT (Generative Pre-trained Transformer)**: Text generation with attention mechanisms
- **VAE (Variational Autoencoder)**: Latent space modeling for data generation
- **GAN (Generative Adversarial Network)**: Adversarial training for realistic data synthesis
- **Diffusion Models**: State-of-the-art image and data generation

## ğŸ“ Project Structure

```
gen_ai_project/
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ gpt_config.yaml    # GPT model configuration
â”‚   â”œâ”€â”€ vae_config.yaml    # VAE model configuration
â”‚   â”œâ”€â”€ gan_config.yaml    # GAN model configuration
â”‚   â””â”€â”€ diffusion_config.yaml
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ models/            # Model implementations
â”‚   â”œâ”€â”€ training/          # Training scripts
â”‚   â””â”€â”€ evaluation/        # Evaluation utilities
â”œâ”€â”€ data/                   # Dataset storage
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ examples/              # Usage examples
â””â”€â”€ requirements.txt       # Dependencies
```

## ğŸ› ï¸ Installation

```bash
# Clone the repository
cd gen_ai_project

# Install dependencies
pip install -r requirements.txt

# Run setup
python setup.py develop
```

## ğŸš€ Quick Start

### Text Generation with GPT
```python
from src.models.gpt import GPTModel
from src.training.gpt_trainer import GPTTrainer

# Load configuration
config = load_config('config/gpt_config.yaml')

# Initialize model
model = GPTModel(config)

# Train model
trainer = GPTTrainer(model, config)
trainer.train(dataset)

# Generate text
generated_text = model.generate("The future of AI is")
print(generated_text)
```

### Image Generation with Diffusion
```python
from src.models.diffusion import DiffusionModel

# Initialize model
model = DiffusionModel.from_pretrained('config/diffusion_config.yaml')

# Generate images
images = model.sample(num_samples=4)
```

## ğŸ“Š Model Architectures

### GPT (Generative Pre-trained Transformer)
- Multi-head self-attention
- Position encoding
- Layer normalization
- Residual connections

### VAE (Variational Autoencoder)
- Encoder-decoder architecture
- Latent space sampling
- KL divergence regularization
- Reconstruction loss

### GAN (Generative Adversarial Network)
- Generator network
- Discriminator network
- Adversarial training
- Progressive training support

### Diffusion Models
- Forward diffusion process
- Reverse diffusion process
- U-Net architecture
- Noise scheduling

## ğŸ“ Examples

Check out the `examples/` directory for detailed usage examples:
- `text_generation_example.py`: Complete GPT implementation
- `image_generation_example.py`: VAE and GAN examples
- `diffusion_example.py`: Diffusion model usage

## ğŸ“ˆ Training

Each model comes with optimized training scripts:

```bash
# Train GPT model
python src/training/train_gpt.py --config config/gpt_config.yaml

# Train VAE model
python src/training/train_vae.py --config config/vae_config.yaml

# Train GAN model
python src/training/train_gan.py --config config/gan_config.yaml

# Train Diffusion model
python src/training/train_diffusion.py --config config/diffusion_config.yaml
```

## ğŸ§ª Evaluation

Comprehensive evaluation metrics for each model type:

- **Text Generation**: Perplexity, BLEU score, Human evaluation
- **Image Generation**: FID, IS, LPIPS
- **General**: Reconstruction loss, Sampling quality

## ğŸ”§ Configuration

Each model has detailed configuration files in the `config/` directory. Customize:
- Model architecture parameters
- Training hyperparameters
- Data preprocessing settings
- Evaluation metrics

## ğŸ“š Documentation

- [Model Architecture Details](docs/architectures.md)
- [Training Guide](docs/training.md)
- [API Reference](docs/api.md)
- [Best Practices](docs/best_practices.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- Attention Is All You Need (Transformer paper)
- Auto-Encoding Variational Bayes (VAE paper)
- Generative Adversarial Networks (GAN paper)
- Denoising Diffusion Probabilistic Models (DDPM paper)

---

**Built with â¤ï¸ for the AI community**